# Game Theory Trust Suite ðŸŽ®ðŸ§ 

*Interactive explorations of trust, cooperation, and AI alignment through game theory*

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/HillaryDanan/game-theory-trust-suite/blob/main/notebooks/)

## Overview

A collection of one-click Google Colab notebooks that make game theory concepts tangible through interactive visualizations. Built for AI safety researchers, students, and anyone interested in trust dynamics.

## ðŸš€ Quick Start

Each notebook runs with zero setup - just click and play!

| Notebook | Description | Open in Colab |
|----------|-------------|---------------|
| 1. Trust Dynamics Playground | Explore how trust emerges and evolves through game theory | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/HillaryDanan/game-theory-trust-suite/blob/main/notebooks/1_Trust_Dynamics_Playground.ipynb) |
| 2. Human-AI Trust Laboratory | Build trust with AI agents that learn from your behavior | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/HillaryDanan/game-theory-trust-suite/blob/main/notebooks/2_Human_AI_Trust_Laboratory.ipynb) |
| 3. Adaptive Strategy Game | Explore multi-dimensional strategy alignment | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/HillaryDanan/game-theory-trust-suite/blob/main/notebooks/3_Adaptive_Strategy_Game.ipynb) |
| 4. Trust Network Evolution | Watch trust propagate through multi-agent networks | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/HillaryDanan/game-theory-trust-suite/blob/main/notebooks/4_Trust_Network_Evolution.ipynb) |

## ðŸŽ¨ Design Philosophy

- **One-click execution**: Zero setup, instant gratification
- **Progressive complexity**: Start simple, reveal depth through interaction
- **Beautiful visualizations**: Clean, purposeful aesthetics that teach
- **Scientific accuracy**: Based on established game theory and network science

## ðŸ§ª Key Concepts Explored

- **Trust Formation**: How repeated interactions build or destroy trust
- **Strategic Behavior**: Game-theoretic optimal strategies for cooperation
- **AI Alignment**: Creating AI agents that cooperate with human values
- **Network Effects**: How trust spreads through social connections
- **Adaptive Strategies**: Multi-dimensional approach to cooperation

## ðŸ“Š Mathematical Foundations

The implementations are based on established research:
- Axelrod's evolution of cooperation
- Nowak's five mechanisms for cooperation
- Network resilience patterns from BarabÃ¡si
- Trust calibration frameworks from human-AI interaction research

## ðŸ“š References

- Axelrod, R. (1984). The Evolution of Cooperation
- Nowak, M. A. (2006). Five Rules for the Evolution of Cooperation
- Okamura, K., & Yamada, S. (2020). Adaptive trust calibration for human-AI collaboration
- Ji et al. (2023). AI Alignment: A Comprehensive Survey

---

*Remember: Trust is earned in drops and lost in buckets. These simulations let you explore that dynamic safely.* ðŸŽ®âœ¨
